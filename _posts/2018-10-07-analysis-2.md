---
layout: post
title: '이리의 데이터 분석 도전기2 - 주식 데이터 분석 project'
author: Idea
date: 2018-10-07 23:30
tags: [data-analytics,deeplearning]
image: /files/covers/road.jpg
---

# 분석을 위한 도구 모음집

## <span style="color:DarkOrchid"> 주식데이터 분석 프로젝트 </span>
이 시리즈의 지난 편에서는 앞으로
1. 시계열 데이터(주식데이터)를 가지고
2. 딥러닝을 할건데
3. 감성분석까지 해서 성능을 높여보겠다

라는 목적 하에 몇가지 유용한 논문을 찾아 정리해 보며 분석에 대한 감각을 일깨워 보았습니다.

이번에는 직접적으로 분석을 위한 도구가 되는 RNN에 대해서 다루어 보려고 합니다. 이후로는
- 감성분석
- 시계열 데이터의 전처리
- 연구 프레임 (해당 데이터 분석 프로젝트의 프레임 워크)
- 직접 코딩하여 실현

하는 등의 주제로 글을 쓸 계획입니다. <span style="color:LightBlue "> 더 공부해야 할 것이 많을 가능성이 농후하기에 이 계획은 한없이 늘어날 수 있습니다(...!)</span>


### 0. 일단 RNN
딥러닝의 첫 포스팅부터 RNN이라니 뭔가 걷기도 전에 뛰는 기분이지만 먼저 여기서 필요한 것부터 다루고, 딥러닝에 관한 포스팅은 차근차근 기본부터 해나가도록 하겠습니다.

![네, 피사의 사탑마냥 아주 위태롭게 쌓아놓았습니다. 저는 일단해보고 다시해보자의 정신을 믿습니다...! 좋게 말하면 lean start up 정신이 되겠습니다.](/assets/post_image/pisa.jpg)

저에게는 딥러닝 공부를 위한 비장의 무기가 있었습니다. 바로 친근한 눈높이 강의로 입문의 바이블이 된 홍콩과기대 김성훈 교수님의 딥러닝 강의입니다. edwith에서 저는 수강하고 있지만 따로 가입하는 것이 번거로우시다면 [여기를 누르시면 바로 수강페이지로 이동합니다.](https://hunkim.github.io/ml/)

이번 포스팅의 많은 부분은 김성훈 교수님의 강의를 기반으로 함을 알려드립니다.

### 1. Sequence Data & Why RNN
인간이 대화를 할때 하나의 단어만으로 이야기를 나누지는 않지요, 여러 단어가 모여 문장을 만들고 맥락을 형성합니다. 이런 데이터가 바로 Sequence Data입니다.
- 이전의 정보를 기반으로 이해 될 수 있으며
- NN/CNN로는 이러한 데이터를 다루기 힘듭니다.
- Language Modeling, Speech Recognition, Machine Translation, Conversation Modeling/Question Answering, Image/Video Captioning, Image/Music/Dance Generation 등에 쓰입니다.
- RNN은 Sequence Data를 학습하기 위한 좋은 구조를 가지고 있습니다.

![RNN의 구조_모두의 딥러닝_김성훈 교수님](/assets/post_image/sequencedata.jpg)

즉, 오른쪽 식에서 두번째 박스A에는 input으로
1. X1
1. 이전에 input X0을 넣고 학습되어 나온 첫번째 박스A의 결과

이 두가지가 들어가게 되는 것입니다.
이렇듯 RNN은 이전의 연산이 뒤의 연산에 영향을 미치는 구조로 Series data에 적합한 모델을 형성합니다.

### 2. RNN 식의 구성
- $h_t = yt$ : 새로운 결과값
- $f_W$ : parameter들을 조정하는 식 (Hidden Layer)
- $h_t-1 = y_t-1$ : 이전의 결과 값
- $x_t$ : 해당 시점의 input

![RNN의 식_모두의 딥러닝_김성훈 교수님](/assets/post_image/sequencedata.jpg)

**여기서, RNN을 박스 하나로 표현하는 이유는 **$f_W$** 라는 식**(이전시점의 output과 현재의 input 두가지 값을 input으로 갖는 식!)**을 동일하게 모든 RNN에 계속 가져가는 것이기 때문입니다.**
<span style="color:LightBlue ">식에 넣었다가 값얻어서 또 새 데이터랑 또 넣고 또 값얻어서 같은 식에 새 데이터랑 또 넣고... 반복</span>

**가장 기본인, <span style="color:Gold"> Vanilla RNN </span>**
![Vanilla RNN_모두의 딥러닝_김성훈 교수님](/assets/post_image/weight.jpg)
- $W$들은 weight, 즉 가중치를 뜻합니다.
- Hidden Layer식을 보시면
$tanh$(이전가중치x이전output + 현재가중치x현재input)
임을 알 수 있습니다.
- $y_t$에서는 또 다시 그 시점에 계산된 output에 대해 가중치를 부여합니다.

여기서 아! 할 수 있는것이, 기존의 투자론 관련 이론에서는 시간에 따라 가중치를 두는데(당연히 근래의 것일 수록 가중치가 높아짐),  **<span style="color:DarkOrchid">*컴퓨터를 통해서는 그 식을 제가 가장 '최적'이라 생각하는 대로 수월하게 조절이 가능하다는 이점입니다.*</span>** 당연하게 들릴 수 도 있겠지만 책속의 이론들이 컴퓨터로 오게 되면서 그 자유도와 복잡도가 훨씬 늘 수 있게 되었다는 생각이 들었습니다. (계산은 컴퓨터가 하지 제가 하는게 아니니까요...!)

더불어, 머신러닝을 한창 배울 때 봤던 비슷한 게 떠올랐습니다.
![Boosting_SANG WON PARK](/assets/post_image/boosting.jpg)
[원본 영상은 Udacity,여기 NanoDegree과정에도 관심이 많은데 기회가 되면 포스팅하도록 하겠습니다.](https://www.youtube.com/watch?v=GM3CDQfQ4sw)
[저만 알고 싶었던 SANG WON PARK님의 슬라이드 쉐어, 참 깔끔하고 직관적인 설명에 항상 감탄합니다. ](https://www.slideshare.net/freepsw
)

boosting 기법입니다. 보통 bagging과 대비되어 많이 설명되는데 앞의 모델의 결과가 뒤의 모델에 영향을 미친다는 점이 가장 다릅니다.이러한 기법을 이용해서 굳이 딥러닝까지 오지 않아도 머신러닝 기법을 앙상블한 Xgboost등으로 꽤 좋은 성과를 낼 수 있습니다.
**<span style="color:DarkOrchid">*이전의 결과를 다음의 학습에 이용한다*</span>** 는 아이디어는 참 멋진 효과를 지니고 있다고 생각했습니다. 특히나 그 데이터가 지금처럼 시계열일때에는 필수적이겠지요.

### 3. RNN 활용 간단 예제
![Boosting_SANG WON PARK](/assets/post_image/examplernn.jpg)
- 각각의 입력을 vector로 표현하기 위해 one-hot encoding을 사용했습니다. 'hello'에는 각기 다른 값이 4개 이므로 4개의 자리로 표현할 수 있습니다.
- hidden layer를 거치며 각각의 weight를 통해 계산에 영향을 미치고
- output을 냅니다.
파란 박스 부분을 보시면 가장 큰 값이 input의 1이된다고 생각하시면 됩니다.
다음에 어떤 철자가 올 지 예측한 것을 알 수 있습니다.
- 두번째 박스는 예측에 실패했습니다. 'l'자리에 'o'가 나와버렸네요. 이런것이 'error'입니다.

### 4. RNN의 다양한 활용
![flexibility of RNN_모두의 딥러닝_김성훈 교수님](/assets/post_image/rnnflexibility.jpg)

- one to one: 기본
- one to many: Image Captioning을 할 수 있습니다. 요즘에 파워포인트에 사진만 붙여넣어도 어떤 대상인지 잘 분류해서 적어주는거, 느껴보셨나요?
- many to one: Sentiment Classification을 할 수 있습니다. 여러 단어들로 이루어진 문장을 넣 그 문장이 뜻하는 '슬픔', '기쁨' 과 같은 'sentiment'로 y값을 얻을 수 있습니다.
- many to many: Machine Translation을 할 수 있습니다. 영어 문장 긁어서 넣으면 한국어 문장으로 구글이 잘 번역해 줍니다.
- many to many 2 : Video classification on frame level 비디오는 여러개의 프레임이 존재합니다. 각 프레임들을 input으로 받아 어떤 것인지로 각각 분류가 가능합니다.

![Multi-Layer RNN_모두의 딥러닝_김성훈 교수님](/assets/post_image/multirnn.jpg)

RNN의 레이어를 여러개를 준다면 더 복잡한 학습도 가능하겠지요!

### 5. Several advanced models
오늘 정리한 내용은 말 그대로 기본 RNN, 즉 Vanilla RNN에 관한 것이였습니다. 레이어들이 많아지다보면 학습하는 데 당연히 어려움이 생길 수 있습니다. 이러한 점을 극복하기 위해 보통은 RNN자체를 사용하기보단 다음의 모델들을 사용하고 있다고 합니다.
- Long Shor Term Memory (LSTM)
- GRU by Cho et al.2014
---
### Vanilla RNN에 나온 tanh가 혹시 궁금하다면
![tanh VS sigmoid_TAEWAN.KIM](/assets/post_image/tanh.jpg)
간단히는, Sigmoid의 대체제로 사용될 수 있는 활성화 함수입니다.
[여기에서 자세한 차이점과 식을 보실 수 있습니다.](http://taewan.kim/post/tanh_diff/)

---
Reference:
- [김성훈 교수님의 모두를 위한 머신러닝과 딥러닝의 강의](https://hunkim.github.io/ml/)
- Photo by Alex Plesovskich on Unsplash
- Photo by Hao Zhang on Unsplash
